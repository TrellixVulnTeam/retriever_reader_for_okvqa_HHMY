{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.nli\n",
    "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/snli-roberta-large-2020.04.30.tar.gz\", predictor_name=\"textual-entailment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entailment_score(hypothesis:List, premises:List, thredshold:float)->float:\n",
    "    semantic_score, valid = 0, 0\n",
    "    assert len(hypothesis) == len(premises), print(\"the length of hypothesis should be the same\")\n",
    "    for hyp, pre in zip(hypothesis, premises):\n",
    "        score = predictor.predict(hypothesis=hyp, premise=pre)['probs'][0]\n",
    "        semantic_score += score if score > thredshold else 0.0\n",
    "        valid +=1 if score > thredshold else 0\n",
    "    return semantic_score/valid if valid else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(file):\n",
    "    with open(file) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = read_json(\"result_output_updated.json\")\n",
    "prediction = prediction[:10] # for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:20<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the semantic evaluation score for the model is 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.5 # set the threshold of nli_score be 0.5\n",
    "model_evaluation_score= 0 \n",
    "for pred in tqdm(prediction):\n",
    "    model_pred = pred['pred']\n",
    "    ref = pred['ref']\n",
    "    label_score = pred['score']\n",
    "    pred_score = 0\n",
    "    most_similar_label = \"\"\n",
    "    for label, premises in ref.items():\n",
    "        if premises: # if the premises is not empty\n",
    "            hypothesis = [prem.replace(label, model_pred) for prem in premises]\n",
    "            nli_score=entailment_score(hypothesis, premises, threshold) \n",
    "            if nli_score > pred_score:\n",
    "                pred_score = nli_score\n",
    "                most_similar_label = label\n",
    "    # print(most_similar_label,pred_score)\n",
    "    if pred_score:\n",
    "        model_evaluation_score+=pred_score * label_score[most_similar_label] # multiply the nli score with the original score. \n",
    "print(\"the semantic evaluation score for the model is {:.2f}\".format(model_evaluation_score/len(prediction)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e3af51a794074cca00f16dcc18d2f714c95d1c9536d76d5db0428cfed29f4e8d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
